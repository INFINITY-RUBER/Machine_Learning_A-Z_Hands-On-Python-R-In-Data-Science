library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(tidytext)
install.packages("tidytext")
install.packages("reshape2")
install.packages("RWeka")
install.packages("knitr")
install.packages("knitr")
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(tidytext)
install.packages("tidytext")
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(tidytext)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
install.packages("RWeka")
install.packages("RWeka")
install.packages(c("crosstalk", "Rcpp", "shiny"))
install.packages(c("knitr", "gridExtra", "grid", "magick", "ggimage", "igraph", "ggraph", "tidytext"))
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
install.packages(c("ggimage", "magick", "memery", "RWeka", "tidytext"))
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
install.packages(c("ggimage", "magick", "memery", "RWeka", "tidytext"))
install.packages("Cairo")
install.packages("Cairo")
install.packages("magickGUI")
install.packages("tidytext")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
install.packages("RWekajars")
install.packages("rJava")
rJavarJavarJavarJava
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
#library(RWeka)
library(knitr)
library(gridExtra)
library(grid)
library(magick)
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
#library(RWeka)
library(knitr)
library(gridExtra)
library(grid)
#library(magick)
library(memery)
install.packages("memery")
install.packages("Cairo")
install.packages("cairoDevice")
install.packages("memery")
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
#library(RWeka)
library(knitr)
library(gridExtra)
library(grid)
#library(magick)
library(memery)
#library(magick)
library(memery)
library(ggimage)
library(igraph)
library(ggraph)
library(tidytext)
install.packages("tidytext")
install.packages("ISOcodes")
install.packages("stopwords")
install.packages("tidytext")
install.packages("ISOcodes")
# Read the data
scripts <- read.csv("../input/lord-of-the-rings-data/lotr_scripts.csv", sep=",")
# Read the data
scripts <- read.csv("../input/lord-of-the-rings-data/lotr_scripts.csv", sep=",")
# Read the data
scripts <- read.csv("../input/lord-of-the-rings-data/lotr_scripts.csv", sep=",")
# Read the data
scripts <- read.csv("/lotr_scripts.csv", sep=",")
# Read the data
scripts <- read.csv("./lotr_scripts.csv", sep=",")
# First 10 rows
kable(head(scripts))
# Last 10 rows
kable(tail(scripts))
# Summary
kable(summary(scripts))
# Structure
str(scripts)
# Text transformations
cleanCorpus <- function(corpus){
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus.tmp, stripWhitespace)
corpus.tmp <- tm_map(corpus.tmp, content_transformer(tolower))
v_stopwords <- c(stopwords("english"), c("thats","weve","hes","theres","ive","im",
"will","can","cant","dont","youve","us",
"youre","youll","theyre","whats","didnt"))
corpus.tmp <- tm_map(corpus.tmp, removeWords, v_stopwords)
corpus.tmp <- tm_map(corpus.tmp, removeNumbers)
return(corpus.tmp)
}
# Text transformations
cleanCorpus <- function(corpus){
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus.tmp, stripWhitespace)
corpus.tmp <- tm_map(corpus.tmp, content_transformer(tolower))
v_stopwords <- c(stopwords("english"), c("thats","weve","hes","theres","ive","im",
"will","can","cant","dont","youve","us",
"youre","youll","theyre","whats","didnt"))
corpus.tmp <- tm_map(corpus.tmp, removeWords, v_stopwords)
corpus.tmp <- tm_map(corpus.tmp, removeNumbers)
return(corpus.tmp)
}
# Most frequent terms
frequentTerms <- function(text){
s.cor <- VCorpus(VectorSource(text))
s.cor.cl <- cleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.999)
m <- as.matrix(s.tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
return(dm)
}
# Define bigram tokenizer
tokenizer2  <- function(x){
NGramTokenizer(x, Weka_control(min=2, max=2))
}
# Define trigram tokenizer
tokenizer3  <- function(x){
NGramTokenizer(x, Weka_control(min=3, max=3))
}
# Most frequent bigrams
frequentBigrams <- function(text){
s.cor <- VCorpus(VectorSource(text))
s.cor.cl <- cleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl, control=list(tokenize=tokenizer2))
s.tdm <- removeSparseTerms(s.tdm, 0.999)
m <- as.matrix(s.tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
return(dm)
}
# Most frequent trigrams
frequentTrigrams <- function(text){
s.cor <- VCorpus(VectorSource(text))
s.cor.cl <- cleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl, control=list(tokenize=tokenizer3))
s.tdm <- removeSparseTerms(s.tdm, 0.999)
m <- as.matrix(s.tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
return(dm)
}
# Top 15 characters with more dialogues (absolute values)
scripts %>%
count(char) %>%
arrange(desc(n)) %>%
slice(1:15) %>%
ggplot(aes(x=reorder(char, n), y=n)) +
geom_bar(stat="identity", aes(fill=n), show.legend=FALSE) +
geom_label(aes(label=n)) +
scale_fill_gradient(low="paleturquoise", high="paleturquoise4") +
labs(x="Character", y="Lines of dialogue",
title="Lines of dialogue per character (absolute values)") +
coord_flip() +
theme_bw()
# Image in the visualization
image <- image_read("../input/the-lord-of-the-rings-figures/gollum.gif")
install.packages("memery")
install.packages("memery")
# Load libraries
library(tidyverse)
library(tm)
library(wordcloud)
library(wordcloud2)
library(reshape2)
library(RWeka)
install.packages("RWeka")
library(RWeka)
library(knitr)
library(gridExtra)
library(grid)
library(magick)
install.packages("magick")
library(grid)
library(magick)
install.packages("magick")
library(grid)
library(magick)
library(memery)
install.packages("memery")
library(magick)
library(memery)
library(ggimage)
library(memery)
install.packages("memery")
install.packages("cowplot")
install.packages("memery")
# Top 15 characters with more dialogues (relative values)
scripts %>%
count(char) %>%
arrange(desc(n)) %>%
slice(1:15) %>%
mutate(Percentage=n/nrow(scripts)) %>%
ggplot(aes(x=reorder(char, Percentage), y=Percentage)) +
geom_bar(stat="identity", aes(fill=Percentage), show.legend=FALSE) +
geom_label(aes(label=paste0(round(Percentage*100, 2), "%"))) +
scale_y_continuous(labels=scales::percent) +
scale_fill_gradient(low="paleturquoise", high="paleturquoise4") +
labs(x="Character", y="Lines of dialogue (%)",
title="Lines of dialogue per character (relative values)") +
coord_flip() +
theme_bw()
# Image in the visualization
image <- image_read("../input/the-lord-of-the-rings-figures/sauron.png")
grid.raster(image, x=0.85, y=0.26, height=0.34)
# Top 15 characters with more dialogues (relative values)
scripts %>%
count(char) %>%
arrange(desc(n)) %>%
slice(1:15) %>%
mutate(Percentage=n/nrow(scripts)) %>%
ggplot(aes(x=reorder(char, Percentage), y=Percentage)) +
geom_bar(stat="identity", aes(fill=Percentage), show.legend=FALSE) +
geom_label(aes(label=paste0(round(Percentage*100, 2), "%"))) +
scale_y_continuous(labels=scales::percent) +
scale_fill_gradient(low="paleturquoise", high="paleturquoise4") +
labs(x="Character", y="Lines of dialogue (%)",
title="Lines of dialogue per character (relative values)") +
coord_flip() +
theme_bw()
# Image in the visualization
image <- image_read("./unnamed-chunk-15-1.pngsauron.png")
# Image in the visualization
image <- image_read("./unnamed-chunk-15-1.pngsauron.png")
grid.raster(image, x=0.85, y=0.26, height=0.34)
install.packages(c("ggimage", "memery", "tidytext"))
# Text transformations
cleanCorpus <- function(corpus){
corpus.tmp <- tm_map(corpus, removePunctuation)
corpus.tmp <- tm_map(corpus.tmp, stripWhitespace)
corpus.tmp <- tm_map(corpus.tmp, content_transformer(tolower))
v_stopwords <- c(stopwords("english"), c("thats","weve","hes","theres","ive","im",
"will","can","cant","dont","youve","us",
"youre","youll","theyre","whats","didnt"))
corpus.tmp <- tm_map(corpus.tmp, removeWords, v_stopwords)
corpus.tmp <- tm_map(corpus.tmp, removeNumbers)
return(corpus.tmp)
}
# Most frequent terms
frequentTerms <- function(text){
s.cor <- VCorpus(VectorSource(text))
s.cor.cl <- cleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl)
s.tdm <- removeSparseTerms(s.tdm, 0.999)
m <- as.matrix(s.tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
return(dm)
}
# Define bigram tokenizer
tokenizer2  <- function(x){
NGramTokenizer(x, Weka_control(min=2, max=2))
}
# Define trigram tokenizer
tokenizer3  <- function(x){
NGramTokenizer(x, Weka_control(min=3, max=3))
}
# Most frequent bigrams
frequentBigrams <- function(text){
s.cor <- VCorpus(VectorSource(text))
s.cor.cl <- cleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl, control=list(tokenize=tokenizer2))
s.tdm <- removeSparseTerms(s.tdm, 0.999)
m <- as.matrix(s.tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
return(dm)
}
# Most frequent trigrams
frequentTrigrams <- function(text){
s.cor <- VCorpus(VectorSource(text))
s.cor.cl <- cleanCorpus(s.cor)
s.tdm <- TermDocumentMatrix(s.cor.cl, control=list(tokenize=tokenizer3))
s.tdm <- removeSparseTerms(s.tdm, 0.999)
m <- as.matrix(s.tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
return(dm)
}
# Top 15 characters with more dialogues (absolute values)
scripts %>%
count(char) %>%
arrange(desc(n)) %>%
slice(1:15) %>%
ggplot(aes(x=reorder(char, n), y=n)) +
geom_bar(stat="identity", aes(fill=n), show.legend=FALSE) +
geom_label(aes(label=n)) +
scale_fill_gradient(low="paleturquoise", high="paleturquoise4") +
labs(x="Character", y="Lines of dialogue",
title="Lines of dialogue per character (absolute values)") +
coord_flip() +
theme_bw()
# Image in the visualization
image <- image_read("../input/the-lord-of-the-rings-figures/gollum.gif")
# Top 15 characters with more dialogues (relative values)
scripts %>%
count(char) %>%
arrange(desc(n)) %>%
slice(1:15) %>%
mutate(Percentage=n/nrow(scripts)) %>%
ggplot(aes(x=reorder(char, Percentage), y=Percentage)) +
geom_bar(stat="identity", aes(fill=Percentage), show.legend=FALSE) +
geom_label(aes(label=paste0(round(Percentage*100, 2), "%"))) +
scale_y_continuous(labels=scales::percent) +
scale_fill_gradient(low="paleturquoise", high="paleturquoise4") +
labs(x="Character", y="Lines of dialogue (%)",
title="Lines of dialogue per character (relative values)") +
coord_flip() +
theme_bw()
# Image in the visualization
image <- image_read("../input/the-lord-of-the-rings-figures/sauron.png")
# Lines of dialogue per character
plot1 <- scripts %>%
filter(char %in% c("FRODO", "SAM", "GANDALF", "ARAGORN", "PIPPIN",
"MERRY", "GOLLUM", "GIMLI", "THEODEN", "FARAMIR",
"EOWYN", "LEGOLAS", "SMEAGOL", "TREEBEARD", "BILBO")) %>%
count(movie, char) %>%
ggplot(aes(x=reorder(char, n, sum), y=n)) +
geom_bar(stat="identity", aes(fill=movie)) +
labs(x="Character", y="Lines of dialogue",
title="Lines of dialogue per character") +
theme_bw() +
theme(legend.position="bottom",
legend.title=element_blank()) +
coord_flip()
# Lines of dialogue per movie (%)
plot2 <- scripts %>%
count(movie) %>%
mutate(Percentage=paste0(round(n/sum(n)*100, 2), "%")) %>%
ggplot(aes(x=factor(1), y=n, fill=movie)) +
geom_bar(stat="identity", width=1, size=1, color="white", show.legend=FALSE) +
coord_polar(theta="y") +
labs(title="Lines of dialogue per movie (%)") +
theme_void() +
geom_text(aes(label=Percentage),
position=position_stack(vjust = 0.5))
# Subplot
grid.arrange(plot1, plot2, ncol=2)
# Transform the text to a tidy data structure with one token per row
tokens <- scripts %>%
mutate(dialogue=as.character(scripts$dialog)) %>%
unnest_tokens(word, dialogue)
# Transform the text to a tidy data structure with one token per row
tokens <- scripts %>%
mutate(dialogue=as.character(scripts$dialog)) %>%
unnest_tokens(word, dialogue)
# Transform the text to a tidy data structure with one token per row
tokens <- scripts %>%
mutate(dialogue=as.character(scripts$dialog)) %>%
unnest_tokens(word, dialogue)
# Positive and negative words
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort=TRUE) %>%
acast(word ~ sentiment, value.var="n", fill=0) %>%
comparison.cloud(colors=c("#F8766D", "#00BFC4"), max.words=100)
# Frequency associated with each sentiment
sentiments <- tokens %>%
inner_join(get_sentiments("nrc")) %>%
count(sentiment, sort=TRUE)
install.packages("tokenizers")
# Positive and negative words
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort=TRUE) %>%
acast(word ~ sentiment, value.var="n", fill=0) %>%
comparison.cloud(colors=c("#F8766D", "#00BFC4"), max.words=100)
# Positive and negative words
tokens %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort=TRUE) %>%
acast(word ~ sentiment, value.var="n", fill=0) %>%
comparison.cloud(colors=c("#F8766D", "#00BFC4"), max.words=100)
# Transform the text to a tidy data structure with one token per row
tokens <- scripts %>%
mutate(dialogue=as.character(scripts$dialog)) %>%
unnest_tokens(word, dialogue)
# Lines of dialogue per character
plot1 <- scripts %>%
filter(char %in% c("FRODO", "SAM", "GANDALF", "ARAGORN", "PIPPIN",
"MERRY", "GOLLUM", "GIMLI", "THEODEN", "FARAMIR",
"EOWYN", "LEGOLAS", "SMEAGOL", "TREEBEARD", "BILBO")) %>%
count(movie, char) %>%
ggplot(aes(x=reorder(char, n, sum), y=n)) +
geom_bar(stat="identity", aes(fill=movie)) +
labs(x="Character", y="Lines of dialogue",
title="Lines of dialogue per character") +
theme_bw() +
theme(legend.position="bottom",
legend.title=element_blank()) +
coord_flip()
# Lines of dialogue per movie (%)
plot2 <- scripts %>%
count(movie) %>%
mutate(Percentage=paste0(round(n/sum(n)*100, 2), "%")) %>%
ggplot(aes(x=factor(1), y=n, fill=movie)) +
geom_bar(stat="identity", width=1, size=1, color="white", show.legend=FALSE) +
coord_polar(theta="y") +
labs(title="Lines of dialogue per movie (%)") +
theme_void() +
geom_text(aes(label=Percentage),
position=position_stack(vjust = 0.5))
# Subplot
grid.arrange(plot1, plot2, ncol=2)
setwd("~/Documentos/CURSOS/CURSOS UDEMY/Curso_de_Machine_learning_A_Z_Pytho_R/cogidos/Machine Learning A-Z (Codes and Datasets)/Part 1 - Data Preprocessing/Section 2 -------------------- Part 1 - Data Preprocessing --------------------/R")
# Importing the dataset
dataset = read.csv('Data.csv')
View(dataset)
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age), # remplazar los nan de la columna AGE
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),# remplazar los nan de la columna Salary
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
# Importing the dataset
dataset = read.csv('Data.csv')
# Taking care of missing data
dataset$Age = ifelse(is.na(dataset$Age),
ave(dataset$Age, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Age)
dataset$Salary = ifelse(is.na(dataset$Salary),
ave(dataset$Salary, FUN = function(x) mean(x, na.rm = TRUE)),
dataset$Salary)
View(dataset)
View(dataset)
# Encoding categorical data
dataset$Country = factor(dataset$Country,
levels = c('France', 'Spain', 'Germany'),
labels = c(1, 2, 3))
dataset$Purchased = factor(dataset$Purchased, # codificamos las Purchased en numeros de 0-1
levels = c('No', 'Yes'),
labels = c(0, 1))
# Importing the dataset
dataset = read.csv('Data.csv')
# Splitting the dataset into the Training set and Test set
install.packages('caTools')
install.packages("caTools")
update R
intall update R
